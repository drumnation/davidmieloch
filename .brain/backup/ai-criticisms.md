# AI Coding Mandates: Criticisms from Experienced Developers

This document collects key criticisms and concerns about AI coding tools and their implementation in workplace settings, sourced from experienced developers on Reddit.

## Management Mandates & Implementation Issues

- "Management bought Cursor pro for everyone and said that they expect to see a return on that investment." - The expectation of ROI creates pressure to use AI regardless of actual benefit.

- "One of our OKRs is basically 'Use AI more' and one of the ways they're measuring that is Copilot suggestion acceptance %. Absolute insanity." - Using metrics that incentivize accepting AI suggestions regardless of quality.

- "AI is the new 'Outsource to India'" - Management viewing AI as primarily a cost-cutting measure rather than a tool.

- "Sounds like OP's CTO has been tempted by a shiny new toy. Typical corporate." - Decision makers being swayed by hype rather than demonstrated value.

- "We're offered AI tools if we want them. No mandates. We're being trusted to know when to use them and when not to." - Contrasting example of better implementation.

- "Why people that have no idea about technology are responsible for tech people?" - Criticism of non-technical management making technical tool decisions.

## Quality & Reliability Concerns

- "We're also seeing an increase in failures in Prod, so we need you to really ramp up Copilot and AI code reviews to find the source of these new issues." - Ironic situation where AI is both causing problems and being proposed as the solution.

- "Jeez every time I try to get a solid non trivial piece of code out of AI it sucks. I'd be much better off not asking and just figuring it out. It takes longer and makes me dumber to ask AI." - Criticism of AI's capability with complex code.

- "I tried GitHub Copilot for a while, and while some parts of it were impressive, at most it was an unnecessary convenience that saved only a few seconds of actual work. And it was wrong as many times as it was right. The time I spent correcting its wrong code I could have spent writing the right code myself." - Time savings being offset by error correction time.

- "I had to fix a test that was failing with a new error. I provided the new error to copilot and it gave me the original version of the tests from its first attempt??" - Example of AI repeating mistakes.

- "They're wrong about half the time. There's probably shortcuts to make this easier which I really need to learn to make the transition smoother." - Learning curve issues with AI tools.

## Impact on Developer Skills & Job Satisfaction

- "I am most worried how it affects the bad engineers... my company unfortunately doesn't have the best hiring standards. Every time I hear 'well AI told me this' as defense to a really shitty design decision I die a little inside. Creating tests that do essentially nothing, logging statements that hinder more than help, coding styles that doesn't match the rest of our code base, and just flat out wrong logic are just some examples I have seen." - Concerns about AI enabling and amplifying poor practices.

- "I can't wait to retire." - Extreme job dissatisfaction due to AI mandates.

- "It takes longer and makes me dumber to ask AI." - Concern about skill degradation.

- "Me taking an extra long lunch or finishing early whenever copilot or cursor saves me time." - Developers finding ways to benefit personally rather than increasing productivity.

## Efficiency Claims vs. Reality

- "So far it has helped me most when making quick little Python scripts, using it as an integrated Google in IntelliJ IDE, or creating basic model classes for JSON objects. I do unfortunately spend a lot of time fixing its mistakes or having to get rid of the default suggestions from copilot." - Limited usefulness in specific scenarios, offset by time spent fixing errors.

- "The 'increased efficiency' I get is probably so small it's not recognized. There's way more areas that could be improved for better efficiency with less cost." - Questioning the ROI compared to other potential improvements.

- "Yeah, I tried GitHub Copilot for a while, and while some parts of it were impressive, at most it was an unnecessary convenience that saved only a few seconds of actual work." - Minimal time savings.

- "I think I've heard some numbers throw around like a hope of 5% increased developer efficiency." - Questioning the modest efficiency gains claimed.

## Metrics & Measurement Problems

- "One of our OKRs is basically 'Use AI more' and one of the ways they're measuring that is Copilot suggestion acceptance %." - Problematic metrics that don't measure quality or actual productivity.

- "lol â€” you could end every conversation with Claude/cursor with a request for an estimated time saved and then subtract that from 5pm" - Satirical comment on the arbitrary nature of productivity measurements.

## Broader Industry Concerns

- "Some (many? most?) developers are replacing Google/StackOverflow with ChatGPT or equivalents for many searches. But I don't think most devs are actually getting AI to write code directly." - Observation about actual usage patterns differing from management expectations.

- "It's easy to jump to this cynical take and I'm guilty of it myself. But... better to experiment now and find out how and where it's going to deliver some business value, the alternative is sitting on the fence and then realizing you missed the boat, at which point your competitors have a head start and you likely won't catch them." - Balanced view on the need to explore AI capabilities.

- "I am most worried how it affects the bad engineers." - Concern about AI amplifying existing skill gaps.

## Conclusion

The criticisms highlight a disconnect between management expectations and developer experiences with AI coding tools. The most significant concerns center around:

1. Mandates that prioritize usage metrics over quality outcomes
2. Reliability issues that offset time savings
3. Potential negative impacts on code quality and developer skills
4. Questionable ROI compared to other potential improvements
5. Management decisions driven by hype rather than demonstrated value

The most successful implementations appear to be those where AI tools are offered as optional resources, with developers trusted to determine when and how to use them effectively.